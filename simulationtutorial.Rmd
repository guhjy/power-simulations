---
title: "Power analysis for JCAL special issue"
author: "Joshua Rosenberg"
date: "15/11/2018"
output: pdf_document
---

Adapted from Jessie Sun's excellent tutorial.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

## A Priori Power Analysis

Let's get started with an a priori power analysis. What is the smallest sample size we need to have 80% power to detect an effect size of $\beta_2$ = 0.25, at an alpha level of .05?

First, we need to load the *lavaan* package

```{r}
library(lavaan)
```

Next, we need to specify the population model, based on the assumptions in Figure 2, plus our effect size of interest ($\beta_2$ = 0.25). This is the model that, at the population level, we assume is generating the data that we might see in any given dataset.

Basic *lavaan* notation: a double ~~ denotes variances and covariances, whereas a single ~ denotes a regression path.

```{r}
popmod1 <- '
# variances are fixed at 1
x1~~1*x1
x2~~1*x2
x3~~1*x3
x4~~1*x4
x5~~1*x5
x6~~1*x6
x7~~1*x7
x8~~1*x8
xx1~~1*xx1

# correlation between X1 and X2 is assumed to be .30
# x1~~.3*x2

# regression path is assumed to be .25
y~.25*x1
y~.25*x2
y~.25*x3
y~.25*x4
y~-.25*x5
y~-.25*x6
y~-.25*x7
y~-.25*x8

x1~.25*xx1
x2~.25*xx1
x3~.25*xx1
x4~.25*xx1
x5~-.25*xx1
x6~-.25*xx1
x7~-.25*xx1
x8~-.25*xx1

# # residual variance of Y is 1 - (.1^2 + .2^2) = .95
# y~~.95*y
'

```

We also need to create another *lavaan* model, without those population-level assumptions.

```{r}

fitmod <- '
# # variances of X1 and X2
# x1~~x1
# x2~~x2
# x3~~x3
# x4~~x4
# x5~~x5
# x6~~x6
# x7~~x7
# x8~~x8

# # correlation between X1 and X2
# x1~~x2

# regression path for Y on X1
y~x1
y~x2
y~x3
y~x4
y~x5
y~x6
y~x7
y~x8

# regression path of interest, Y on X2
x1~xx1
x2~xx1
x3~xx1
x4~xx1
x5~xx1
x6~xx1
x7~xx1
x8~xx1


# # residual variance of Y
# y~~y
'
```

To see the logic of the simulation process, let's first just simulate one dataset based on the population model, popmod1.

```{r}
set.seed(20181102)  # setting a seed for reproducibility of the example
data <- simulateData(popmod1, sample.nobs = 300)  # assume 500 participants for now
```

Now, we're going to fit our model (fitmod) to this dataset.

```{r}
fit <- sem(model = fitmod, data=data, fixed.x=F)
```

Here are the parameter estimates. The parameter of interest, y  ~  x2, is in row 5. As you can see, this parameter was statistically significant (*p* < .005) in this simulation based on one dataset.

```{r}
parameterEstimates(fit)  # see all parameters
# parameterEstimates(fit)[5,]  # isolating the row with the parameter of interest
```

However, to estimate power, we need to simulate many datasets. Then, we can obtain the % of datasets in which the parameter of interest is statistically significant. This is our power estimate.

So, let's go ahead and simulate 1000 datasets, still assuming a sample size of 500.

```{r}
library(tidyverse)

f <- function(sample_size_vector, fit_mod, pop_mod, n_iterations) {
    
    simulate_dataset <- function(iteration, fit_mod, pop_mod, sample_size) {
        data <- simulateData(pop_mod, sample.nobs = sample_size)
        fit <- sem(model = fit_mod, data=data, fixed.x = F) 
        d <- as.data.frame(parameterEstimates(fit))[1:16, c(1:7)]
        d$iteration <- iteration
        d
    }
    
    l <- purrr::map_df(.x = 1:n_iterations, .f = simulate_dataset, fit_mod = fitmod, pop_mod=popmod1, sample_size = sample_size_vector)
    
    dl <- l %>% 
        as_tibble() %>% 
        unite(path, lhs, op, rhs, sep = "") %>% 
        group_by(path) %>% 
        summarize(estimated_power = mean(pvalue < .05))
    
    dl$sample_size <- sample_size_vector
    
    dl
}

```

```{r}
ll <- purrr::map_df(.x = seq(50, 400, by = 25), .f = f, fit_mod = fitmod, pop_mod=popmod1, n_iterations = 1000)
```

```{r}
ll %>% group_by(sample_size) %>% summarize(mean_estimate_power = mean(estimated_power))
```

```{r}
```