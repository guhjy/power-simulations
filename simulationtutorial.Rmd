---
title: "Power analysis for TAM and EVT"
author: "Joshua Rosenberg"
date: "11/18/2018"
output:
  html_document:
    df_print: paged
---

Adapted from Jessie Sun's excellent tutorial [here](https://github.com/jessiesunpsych/power-simulations).

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

What is the smallest sample size we need to have 80% power to detect an effect size of $\beta_2$ = 0.25, at an alpha level of .05?

First, we need to load the *lavaan* package. We also load the **tidyverse** package for some manipuation later on.

```{r, loading, setting-up}
library(lavaan)
library(tidyverse)
```

Next, we need to specify the population model, based on the assumptions in Figure 2, plus our effect size of interest ($\beta_2$ = 0.25). This is the model that, at the population level, we assume is generating the data that we might see in any given dataset.

Basic *lavaan* notation: a double ~~ denotes variances and covariances, whereas a single ~ denotes a regression path.

```{r, popmod}
popmod1 <- '
# variances are fixed at 1
x1~~1*x1
x2~~1*x2
x3~~1*x3
x4~~1*x4
x5~~1*x5
x6~~1*x6
x7~~1*x7
x8~~1*x8
xx1~~1*xx1

# regression path is assumed to be .25
y~.25*x1
y~.25*x2
y~.25*x3
y~.25*x4
y~-.25*x5
y~-.25*x6
y~-.25*x7
y~-.25*x8

x1~.25*xx1
x2~.25*xx1
x3~.25*xx1
x4~.25*xx1
x5~-.25*xx1
x6~-.25*xx1
x7~-.25*xx1
x8~-.25*xx1
'

```

We also need to create another *lavaan* model, without those population-level assumptions.

```{r, fitmod}

fitmod <- '
# # variances of X1 and X2
# x1~~x1
# x2~~x2
# x3~~x3
# x4~~x4
# x5~~x5
# x6~~x6
# x7~~x7
# x8~~x8

# regression path for Y on X1
y~x1
y~x2
y~x3
y~x4
y~x5
y~x6
y~x7
y~x8

# regression path of interest, Y on X2
x1~xx1
x2~xx1
x3~xx1
x4~xx1
x5~xx1
x6~xx1
x7~xx1
x8~xx1
'
```

To estimate power, we need to simulate many datasets. Then, we can obtain the % of datasets in which the parameter of interest is statistically significant. This is our power estimate.

So, let's go ahead and simulate 1000 datasets with different sample sizes to determine where the power reaches .90. 

```{r, fit-function}
fit_function <- function(sample_size_vector, fit_mod, pop_mod, n_iterations) {
    
    simulate_dataset <- function(iteration, fit_mod, pop_mod, sample_size) {
        data <- simulateData(pop_mod, sample.nobs = sample_size)
        fit <- sem(model = fit_mod, data=data, fixed.x = F) 
        d <- as.data.frame(parameterEstimates(fit))[1:16, c(1:7)]
        d$iteration <- iteration
        d
    }
    
    l <- purrr::map_df(.x = 1:n_iterations, .f = simulate_dataset, fit_mod = fitmod, pop_mod=popmod1, sample_size = sample_size_vector)
    
    dl <- l %>% 
        as_tibble() %>% 
        unite(path, lhs, op, rhs, sep = "") %>% 
        group_by(path) %>% 
        summarize(estimated_power = mean(pvalue < .05))
    
    dl$sample_size <- sample_size_vector
    
    dl
}

```

Past tests showed that the sample size needed was between 150 and 200, so samples with increments of five between these values are evaluated and presented here. 

```{r, iterate-with-purrr}
ll <- purrr::map_df(.x = seq(150, 200, by = 5), .f = fit_function, fit_mod = fitmod, pop_mod=popmod1, n_iterations = 1000)
```

```{r, present-results}
ll %>% group_by(sample_size) %>% summarize(mean_estimate_power = mean(estimated_power))
```

For a standardized path with an effect of .25, given the only assumptions of the model being the regression paths of interest having this value, a sample size of approximately 175 is needed. 